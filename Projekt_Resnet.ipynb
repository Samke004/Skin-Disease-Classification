{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca747fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "442a8ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboard\n",
    "print(tensorboard.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c161e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "973ef348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nedostajuƒáe slike: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Uƒçitaj metapodatke\n",
    "df = pd.read_csv('dataset/HAM10000_metadata.csv')\n",
    "\n",
    "# 2. Definiraj gdje tra≈æimo slike\n",
    "image_folders = ['dataset/HAM10000_images_part_1', 'dataset/HAM10000_images_part_2']\n",
    "\n",
    "def find_image_path(image_id):\n",
    "    for folder in image_folders:\n",
    "        path = os.path.join(folder, f'{image_id}.jpg')\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None  # Ako ne postoji\n",
    "\n",
    "# 3. Dodaj stupac s punim putanjama do slika\n",
    "df['path'] = df['image_id'].apply(find_image_path)\n",
    "\n",
    "# 4. Kodiranje labela (dijagnoza)\n",
    "label_mapping = {label: idx for idx, label in enumerate(df['dx'].unique())}\n",
    "df['label'] = df['dx'].map(label_mapping)\n",
    "\n",
    "# 5. Provjera ima li slika koje nisu pronaƒëene\n",
    "print(\"Nedostajuƒáe slike:\", df['path'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d4121c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    6705\n",
      "3    1113\n",
      "0    1099\n",
      "5     514\n",
      "6     327\n",
      "4     142\n",
      "2     115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "534c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prvo odvojimo 80% za trening, a 20% za (validacija + test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Sada 20% podijelimo po pola (10% validacija, 10% test)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['label'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df62019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinLesionDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.loc[idx, 'path']\n",
    "        label = self.dataframe.loc[idx, 'label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e28ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# üìê Veliƒçina slike\n",
    "image_size = 224\n",
    "\n",
    "# üß† Toƒçna normalizacija za ResNet50 treniran na ImageNet\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# üîÅ Transformacije za treniranje (s augmentacijom)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# üîç Transformacije za validaciju i test (bez augmentacije)\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# üì¶ Dataseti\n",
    "train_dataset = SkinLesionDataset(train_df, transform=train_transforms)\n",
    "val_dataset = SkinLesionDataset(val_df, transform=eval_transforms)\n",
    "test_dataset = SkinLesionDataset(test_df, transform=eval_transforms)\n",
    "\n",
    "# üöö DataLoaderi\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "599ae624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='runs/skin_diagnosis_experiment1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75762b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Uƒçitaj pretrenirani ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Uzmemo broj znaƒçajki iz zadnjeg sloja\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# Dodamo Dropout + Linear kao zamjenu za originalni fc sloj\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),           # Dropout s 50% ispadanja\n",
    "    nn.Linear(num_features, 7)   # Izlaz za 7 klasa\n",
    ")\n",
    "\n",
    "# Premjesti model na GPU/CPU\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73903f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ResNet50Custom(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        \n",
    "        # Zamjena fc sloja s vi≈°e slojeva: Linear ‚Üí ReLU ‚Üí Dropout ‚Üí Linear (7 klasa)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(512, 7)  # 7 klasa za HAM10000\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "model = ResNet50Custom(dropout_rate=0.5).to(device)\n",
    "##$$$ OVO JE JOS POBOLJSANO S OBZIROM DA JE UZETI I RELU I DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18f46ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52805582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU aktivan: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚úÖ GPU aktivan:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"‚ùå GPU NIJE aktivan ‚Äì koristi≈° CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac64f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Izraƒçunaj te≈æine\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(df['label']),\n",
    "    y=df['label']\n",
    ")\n",
    "\n",
    "# Pretvori u tensor i prebaci na GPU (ako treba)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Dodaj u loss funkciju\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ca4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a190749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return total_loss / len(dataloader.dataset), acc, f1, recall, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d4b3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupno slika: 10015\n",
      "Trening skup: 8012\n",
      "Validacijski skup: 1001\n",
      "Testni skup: 1002\n",
      "\n",
      "Distribucija klasa (trening):\n",
      "label\n",
      "1    5364\n",
      "3     890\n",
      "0     879\n",
      "5     411\n",
      "6     262\n",
      "4     114\n",
      "2      92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribucija klasa (validacija):\n",
      "label\n",
      "1    670\n",
      "3    111\n",
      "0    110\n",
      "5     51\n",
      "6     33\n",
      "4     14\n",
      "2     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Ukupno slika:\", len(df))\n",
    "print(\"Trening skup:\", len(train_df))\n",
    "print(\"Validacijski skup:\", len(val_df))\n",
    "print(\"Testni skup:\", len(test_df))\n",
    "print(\"\\nDistribucija klasa (trening):\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nDistribucija klasa (validacija):\")\n",
    "print(val_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dac66c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4060 Ti\n",
      "Model na: cuda:0\n",
      "Ukupno slika: 10015\n",
      "Train: 8012 | Val: 1001\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Model na:\", next(model.parameters()).device)\n",
    "print(\"Ukupno slika:\", len(df))\n",
    "print(\"Train:\", len(train_df), \"| Val:\", len(val_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f209cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:34<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1/10\n",
      "Train Loss: 1.3509 | Val Loss: 0.9761\n",
      "Train Acc: 0.5627 | Val Acc: 0.6903\n",
      "Train F1: 0.3750 | Val F1: 0.5588\n",
      "‚úÖ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:32<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2/10\n",
      "Train Loss: 1.0022 | Val Loss: 0.9551\n",
      "Train Acc: 0.6408 | Val Acc: 0.6154\n",
      "Train F1: 0.4974 | Val F1: 0.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:34<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3/10\n",
      "Train Loss: 0.8023 | Val Loss: 0.8604\n",
      "Train Acc: 0.6780 | Val Acc: 0.7073\n",
      "Train F1: 0.5623 | Val F1: 0.6080\n",
      "‚úÖ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:37<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4/10\n",
      "Train Loss: 0.7446 | Val Loss: 0.9855\n",
      "Train Acc: 0.7023 | Val Acc: 0.6963\n",
      "Train F1: 0.5814 | Val F1: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:36<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5/10\n",
      "Train Loss: 0.6774 | Val Loss: 1.5900\n",
      "Train Acc: 0.7189 | Val Acc: 0.6503\n",
      "Train F1: 0.6201 | Val F1: 0.5153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:36<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6/10\n",
      "Train Loss: 0.6488 | Val Loss: 0.8746\n",
      "Train Acc: 0.7009 | Val Acc: 0.6533\n",
      "Train F1: 0.5972 | Val F1: 0.5678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:36<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7/10\n",
      "Train Loss: 0.5488 | Val Loss: 0.7017\n",
      "Train Acc: 0.7526 | Val Acc: 0.7862\n",
      "Train F1: 0.6794 | Val F1: 0.6695\n",
      "‚úÖ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:39<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8/10\n",
      "Train Loss: 0.4520 | Val Loss: 0.8373\n",
      "Train Acc: 0.7737 | Val Acc: 0.7882\n",
      "Train F1: 0.7084 | Val F1: 0.7013\n",
      "‚úÖ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:37<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 9/10\n",
      "Train Loss: 0.4086 | Val Loss: 0.9109\n",
      "Train Acc: 0.7949 | Val Acc: 0.7912\n",
      "Train F1: 0.7612 | Val F1: 0.7207\n",
      "‚úÖ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:29<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 10/10\n",
      "Train Loss: 0.3926 | Val Loss: 0.8367\n",
      "Train Acc: 0.7984 | Val Acc: 0.7343\n",
      "Train F1: 0.7576 | Val F1: 0.6275\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/10'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    train_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    train_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    val_loss, val_acc, val_f1, val_recall, val_precision = evaluate_model(model, val_loader)\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)\n",
    "    writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)\n",
    "    writer.add_scalars('F1', {'Train': train_f1, 'Val': val_f1}, epoch)\n",
    "    writer.add_scalars('Recall', {'Train': train_recall, 'Val': val_recall}, epoch)\n",
    "    writer.add_scalars('Precision', {'Train': train_precision, 'Val': val_precision}, epoch)\n",
    "\n",
    "    print(f\"üìä Epoch {epoch+1}/10\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Spremi model ako je najbolji F1\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_resnet50.pth')\n",
    "        print(\"‚úÖ Saved new best model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50f4145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   3%|‚ñé         | 7/251 [00:02<01:42,  2.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/10\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     12\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[52], line 12\u001b[0m, in \u001b[0;36mSkinLesionDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:982\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    980\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 982\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageFile.py:369\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    367\u001b[0m         read_bytes \u001b[38;5;241m=\u001b[39m next_offset \u001b[38;5;241m-\u001b[39m offset\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\JpegImagePlugin.py:415\u001b[0m, in \u001b[0;36mJpegImageFile.load_read\u001b[1;34m(self, read_bytes)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, read_bytes: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m    410\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m    internal: read more image data\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    so libjpeg can finish decoding\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ended\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;66;03m# Premature EOF.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;66;03m# Pretend file is finished adding EOI marker\u001b[39;00m\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_f1 = 0.0\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/10'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    train_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    train_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    val_loss, val_acc, val_f1, val_recall, val_precision = evaluate_model(model, val_loader)\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)\n",
    "    writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)\n",
    "    writer.add_scalars('F1', {'Train': train_f1, 'Val': val_f1}, epoch)\n",
    "    writer.add_scalars('Recall', {'Train': train_recall, 'Val': val_recall}, epoch)\n",
    "    writer.add_scalars('Precision', {'Train': train_precision, 'Val': val_precision}, epoch)\n",
    "\n",
    "    print(f\"üìä Epoch {epoch+1}/10\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_resnet50.pth')\n",
    "        print(\"‚úÖ Saved new best model\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"‚ö†Ô∏è No improvement in F1 for {counter} epoch(s)\")\n",
    "        if counter >= patience:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered\")\n",
    "            break\n",
    "##$$ OVO JE JOS BOLJE≈†ANO S OBZIROM DA JE DODAN EARLY STOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1413ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d6d9985fde17b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d6d9985fde17b9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21cb6918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_12240\\2524842933.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_resnet50.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8004 | Test F1: 0.7003\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
    "model.eval()\n",
    "test_loss, test_acc, test_f1, test_recall, test_precision = evaluate_model(model, test_loader)\n",
    "print(f\"Test Acc: {test_acc:.4f} | Test F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a1708e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x274f5180880>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGzCAYAAAAogL7TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaMklEQVR4nO3dB3gT5R8H8G+6B21pC6WMssveiIgiooyKgCLiQKYg/JmyBQRZCiii4ABxIagg4EARBUFkKSBbmWW0Qhcd0L2b3P9539rQMLQlbZO7+3547klzd0nvuDS/+73ToCiKAiIiItIsB1sfABEREZUuBnsiIiKNY7AnIiLSOAZ7IiIijWOwJyIi0jgGeyIiIo1jsCciItI4BnsiIiKNc4KKmUwmREdHw8vLCwaDwdaHQ0RExSTGdUtNTUWVKlXg4FB6+WdWVhZycnKsfh8XFxe4ublBbVQd7EWgDwoKsvVhEBGRlSIiIlCtWrVSC/S1apTDlTij1e8VGBiI8PBw1QV8VQd7kdELHRq+ACdHV2iF6dR5aI7GRmV29M7/7GmJMSXV1odARWBwUvXX9k3ylFzsNW4yf5+XhpycHBnow4/UgLfXnZcepKSaUKv1Jfl+DPZlqKDoXgR6TQV7gzO0R2PB3uACrTFo8nOnPQaDqr+2b6ssqmK9vRysCvZqps1PDRER0Q2MiglGxbrXqxWDPRER6YIJilyseb1a6bM8g4iISEeY2RMRkS6Y5D/rXq9WDPZERKQLRkWRizWvVysW4xMREWkcM3siItIFk44b6DHYExGRLpigwMhgT0REpF0mHWf2rLMnIiLSOGb2RESkC0Ydt8ZnsCciIl0w/bNY83q1YjE+ERGRxjGzJyIiXTBa2RrfmtfaGoM9ERHpglHJX6x5vVqxGJ+IiEjjmNkTEZEumHTcQI/BvpBVq39ApUoZN63/4Ye6WL6sNca+cAgtW8TCzz8LWZlOOH3GHys/aY7ISG+oRY+BCeg+IAGVgnLk80vn3LBmSSAO71TPOdyoSds0PDkqHsFNM+AfmIc5Q2pi/1YfqMVTwyNwb5cEVKudiZwsB5w55o2Vb9ZEVLiHeZ8xc8+jZbsk+AXkICvDAaePeePTxbUQWWgfNeg5OAF9RsbBr2Iewk67Y/nMqgg9rq5zKPD0mFjc90gygupmy+t2+rAHPplfGZEX3aBWDg4K+k+IxkOPX4NvQC6uxjrjl68qYO07gQAMUDsTDDBacR7i9WrFYF/IuBe6yA97gRo1k7Fw4W7s3Rskn18474edv9ZAXLwnvLyy0b//KcxfsBvPDe4Ok0kdNSLxMc5YubAKosJdYTAo6PJkIuasDMfokHq4dM4dauTmYULYKTf8/KUfZq/8G2rTpE0yNq+tgnMnysHRUcGgCX9j/scn8b8erZGd6Sj3uXCqHHb9EIC4GFd4+eSh35hLePWTkxjSuQ1MJnV8AT3waCKGz47Gu9Oq4exRDzw+LB7z14Zh6P31kXzVGWrTrF06flhVAeeOe8DRScHgaTFY8GUYhj1Q33zd1ObJkVfQfUA83pxYSyYCwc0yMHHx30hPdcT3nwbY+vDICnYRoZYtW4aaNWvCzc0Nbdu2xcGDB21yHMnJbkhMdDcvbe+ORnR0OZz4q6LcvmVLHZw8GYC4WE9cvOCH1aubIiAg45alAfbqj+0+OPSrN6LDXREV5oZVr1dGVroDGrRSzzncSJRKrF5UGftUlM0XNmtYE/yysRIuX/BEeGg5vDW9HgKqZiO4cZp5n60bKuPkYR/ERbnh4uly+GxpTQRUyUZA1SyoRe/hCdi61g/b1vvh8nk3vDO1GrIzDQjpew1qNKNfbWzf4CeDoiileHN8dVSqlovgZplQq0Z3pePAtvI4+KsPYiNd8dtPvji6xxv1m6dDC0yK9Yta2TzYr1+/HhMnTsTs2bNx9OhRNG/eHCEhIYiLi7PpcTk5GfHgQ5ew7edatyy+cnXNQ9cu4YiJ8UR8vDozYlGKIbItVw8TzhzxtPXh0D88vYzyMTX51gVvru5GdOl9BTERbki44go1cHI2ySzx6F4v8zpFMeDYXi80aq3eG83CPL3/uW5J6szqhdOHPdHivlRUrZV/E1mrYQYat0nDoV3qreYrzPhPMb41i1rZvBj/rbfewrBhw/Dcc8/J5ytWrMCPP/6IlStXYtq0aTY7rnbtolCuXC62bxfB/rruPc5j6NC/4O6eh4gIL8x4qSPy8tT1x12zQSaWbjoPF1cTMtMdMO/5WjLTItsTVSv/eykMp45449J5yxuw7n2jMWRyONw9TYgIc8eMIU2Ql2vz+/Ui8fYzwtEJSIq3/MpJTHCSdd5auG4j5kbh5EEPXApV582/sGF5IDy8jPho5ymYjICDI7D6jSrY+Z0/tMBoZcBmsL9DOTk5OHLkCKZPn25e5+DggM6dO2P//v037Z+dnS2XAikpKaV2bCEPh+Pwocq4ds3yD1fU2R87Ggg/v0w80ScU01/ah0kTOyE3Vz0BP/KiK0Z1rS//qO/vnoTJSy9hyhPBDPh2YNSsC6gRnI7Jzza/advOHwJwbJ8v/CrmoPeQSExfehaT+zZHbo46Ar6WjVkQhRoNsjCpV12oWYceiXio1zW8PlbU2bujTuMM/G92BK7GuuCXr7UR8PXKpt8SCQkJMBqNqFSpksV68fzKlSs37b9w4UL4+PiYl6Cg/IZzJS0gIB0tWsRi69baN23LyHBBdLSXrLuf/+q9CApKwb33RUJNRDYY/bcrLpzwwKevVUH4aXf0ej7e1oeleyNfvoC7O17DtIHNcDX25uL5jDQnRF9yl3X3C8Y1RFCtDNmKXw1SrjnCmAeUr5hnsd63Qh4Sb8j21Wb0/Ei07ZKCF/vUQUKMC9Ts+RmRMrvf/YMf/g51x45v/bHx40p4elQMtMCkGKxe1EpVKYEoAUhOTjYvERERpfJ7unQNR3KyKw4erPyv+xn+ue7OzmrufQkYHABnF3Wfg7opMtC363wV0wc3Q2xUEUtYDOK6Kaq5wTz/lwdatk+1KPpu0T4Np494qPa6iUB/78PJePHJOoiNUEf7iX/j6m66qXeHyZT/HaEFRh3X2dv0ElaoUAGOjo6IjY21WC+eBwaKfp2WXF1d4e3tbbGUNNkdrUs4ftle06I7XWBgGp56+jTq1r2GihXT0bBhAl6asQ85OY449B83BfbkuWnRsl96pWrZsu5ePG/WLg07v/WDWrl5GFG7caZchMCgHPlzxar5YwnYu1GzLuLBnnFYNLk+MtMd4VshRy4urvkNvgKrZcq++HUbp6Ji5Sw0bJmCl94+g5xsBxza7Qu1+PbDCuj27DV0fvIagupmYexrkbLb5LZ1fqotun+odyJeG10DmWkO8K2YKxcXN/XeOP/xS3k8MzYGdz+ULL8j7g1JxOPPx2Hfz+VtfWiqNGfOHBgMBoulQYMG5u1ZWVkYPXo0/P39Ua5cOTzxxBM3xcPLly+je/fu8PDwQEBAAKZMmYK8PMsSsqKwafmZi4sLWrdujR07dqBXr15ynclkks/HjBljk2Nq2TJWdqXbts2yCF8E9SaNE9Cr1znZcC8pyRUnT1TExImdZJc9tShfIQ9T3r4Ev4A8ZKQ6IvyMG2Y8W8eilbTa1GueiTe+uWh+PmJutHzctt4Xb06oDnvX49n8ItJFn5+wWC+64IkueTk5DmjcOhmPDYxCOe88JF11lkX5k/o2R/I19RQb797kCx9/IwZOuQJfMajOKXfM6FcLSQnq62Mv9Bx8VT4u/vb6Z08+Hx8ku+Sp0fJZQRg4ORqjX72M8hXyB9XZsqYC1rytnoTm3xjhIJc7f33xNW7cGL/88ov5uZPT9bA7YcIE2SD9q6++klXTIu717t0bv//+e/7vMxploBfJ7759+xATE4OBAwfC2dkZCxYsKNZxGBRFUWzd9W7QoEH44IMPcPfdd2Pp0qXYsGEDzp49e1Nd/o1EAz3xH/RQkylwclR/EVoB04lQaI5tP2YlzrEUSpVszViKDV6p5BgKBQstyFNysTPvG1k1WxqltYVjxY4T1eHpdefBPj3VhE5NLxf5WEVm/9133+H48eM3bRPvUbFiRaxduxZ9+vSR60Tca9iwoWygfs8992DLli3o0aMHoqOjzfFQ9FibOnUq4uPjZcJcVDaviXn66aexePFizJo1Cy1atJD/KVu3bv3PQE9ERGQLKSkpFkvhXmI3On/+PKpUqYLatWujX79+slheED3RcnNzZe+zAqKIv3r16ubeaOKxadOmFvFQjEMjfuepU6eKdcw2D/aCKLq4dOmS/A/7448/5Ch6RERE9thALygoyKJnmOgpdisilq1atUomsO+//z7Cw8Nx//33IzU1VfY4E5l5+fLlb9sbTTzeqrdawbbi0FZ5EBER0W0YFQe53Pnr8x9FT7DCxfii8fitdOvWzfxzs2bNZPCvUaOGrKp2dy/bwZfsIrMnIiJSC+8beoXdLtjfSGTx9erVw4ULF2SjOzGwXFJS0m17o4nHW/VWK9hWHAz2RESkCyYYYIKDFYt1/ezT0tJw8eJFVK5cWfZEE63qRe+zAqGhobJOv127dvK5eDxx4oTFXDHbt2+XNxiNGjUq1u9mMT4REemCsYzHxp88eTJ69uwpi+5Fi3ox4ZsYW6Zv376yrn/o0KFyIjg/Pz8ZwMeOHSsDvGiJL3Tt2lUG9QEDBmDRokWynn7mzJmyb35RSxMKMNgTEZEuGK2usy9eF+LIyEgZ2K9evSq72bVv3x4HDhyQPwtLliyR88GIwXREA3XR0n758uXm14sbg82bN2PkyJHyJsDT01N2VZ83b16xj53BnoiIqBSsW7fuX7e7ublh2bJlcrkdUSrw008/WX0sDPZERKSjOnuDVa9XKwZ7IiLSBZOVw+WaoN6RQNkan4iISOOY2RMRkS4Yy7iBnj1hsCciIl0w/dNf/s5fr95gz2J8IiIijWNmT0REumBUDHKx5vVqxWBPRES6YLSyNb6RxfhERERkr5jZExGRLpgUB7nc+evVm9kz2BMRkS4YdVyMz2BPRES6YLKykZ14vVqxzp6IiEjjmNkTEZEumKweVEe9+bEmgr0hLhEGBxdoxc9Rx6A1IVVaQEuU6lWgOSdToDUGZ+18LxRQcnOgJYqSp6Lhch2gVuo9ciIiItJPZk9ERPRfTJzPnoiISNuMLMYnIiIirWJmT0REumC0elAd9ebHDPZERKQLJsUgF2ter1bqvU0hIiKiImFmT0REumCyshifg+oQERFpftY7B6gVgz0REemCEQa5WPN6tVLvbQoREREVCTN7IiLSBROL8YmIiLTNaGVRvHi9Wqn3NoWIiIiKhJk9ERHpgonF+ERERNpm5EQ4REREpFXM7ImISBcUK+ezF69XKwZ7IiLSBaOOi/EZ7At55MkIdO8TiUpVMuXzS2Hl8OWHtXH49wrmfRo0S8Kg0RdQv2kyTEYDws55YeaoVsjJdoStfb44EF+8FWixrlqdLHyy96zFOkUBZvavjcM7vTH7k3Dc2y3ZvC30uDtWLqiC8395wGBQUL9FBobOjEadxlmwV0+PicV9jyQjqG42crIccPqwBz6ZXxmRF92gBqs++wGVAjNuWv/Dprr4bHUTDBhwEq1ax6JiQAaSk12xf19VfLaqCTIyXKAWar9GQpO7U9HnfzEIbpoB/0q5mDusLvZv8y20h4IBE6PRrW88PL3zcPqwF96dUQPRf6voHNum4clR8fnnGJiHOUNqYv9WH1sfFpUABvtCEmLd8Om7dRF92UMW1nTqGYOXlxzH2GfuweWwcjLQv/LeMWz4tCbef70BjEYDatdLhclkP0U7Nepn4rX1F83PHR2Vm/bZ+FFFGG5xyJnpDpjRrw7u6ZKMMQsi5fmJG4gZz9bBF4dPwckZdqlZu3T8sKoCzh33gKOTgsHTYrDgyzAMe6A+sjNtfxP2X8aN7QIHh+vXqUbNZCx8fTf27gmCv38m/Pyz8PFHzXH5kg8CKqVjzAuH5fr5r9wHtVD7NRLcPIwIP+OBbRsqYtaHF27a/uSIK3hscCwWT6qF2AhXDJwUhfmfn8Pwzk2Qm62OjNDNw4SwU274+Us/zF75N7TGpOMpbm0a7Pfs2YM33ngDR44cQUxMDDZu3IhevXrZ7HgO7qlo8fyzZXXR/ckINGiWLIP98EnnsGldEL76tJZ5n6hLnrAnjo6AX0DebbdfPOmObz6oiHe3nEPfFk0stkVccEVqohMGTrmCgKq5cl3/iVcwolMDxEa6oGqtHNijGf1qWzx/c3x1bDh5CsHNMnHyj3Kwd8nJlpnfU0+fQXRUOZz4S3weDRZBPSamHFZ/2gwvTj0ABwcTTCZ1BBG1XyPh8K7ycrk1BY8PjcWX71XGge352f4bE2th3eHjuLdrInb/4A81EKV9YtEqo5Wz3lnzWluz6ZGnp6ejefPmWLZsGeyNyLQ6hFyBm7sRZ/7ygY9vjgz6SddcsHjVQaz5ZTde//gQGrVIhD2JCndB35aNMeiehnhtdHXERV5Px7MyDHhtdA2Mnh95yxuCanWy4e2bh5+/9EdujgHZmQZs/dIf1YOzEBhkn4H+Vjy988e5Sk1SR8ZYmJOTEQ92uoRtP4sbyltnEZ6eOcjIcFZNoNfaNbqVwKBs+AXk4thv14u8M1KdcPZ4OTRslWbTY6PrCjJ7axa1smlm361bN7nYk5p1U/Hm6kNwcTEhM9MRr0xqjoiwcqjfNElu7/e/MHyyJBgXQ73QqUcMFn5wBCOfbIfoy7bP8Bu0SsfkpZkyaF+Lc8YXbwZi0uPB+GDnWXiUM+GDOVXR6K503Ptwyi1fL/Z545sLmDOkFtYurSTXVamVjQVfXoSjSip8RDuDEXOjcPKgBy6FukNt2t0bhXLlcrF92/XSo8K8vbPRt99pbPnJMlNWE7Vfo1vxDcgvCUtKsPxDEc99K+ZvI7IllXyF58vOzpZLgZSUWwcta0T+7Ykxz9wDz3J5aN85FpPmncKLz98Fh3+SqC3fVMX2TVXlz2Gh3mhx9zV0fSwaq94Nhq21eSjV/HPtRllo0DIDA+5uhD2bysPHPw/Hf/fC8m2ht329yOTfmhSExm3SMX3537IB4tcrAvDygNp496dzcHW/uf7f3oxZEIUaDbIwqVddqFHIw+E4fKgyrl27OQh6eORi7qt7cPmyN7743LIKRk3Ufo1IvUxwkIs1r1crVR35woUL4ePjY16CgoJK/Hfk5TkgJsIDF854ywAuWts/1vcyrsW7yu2i7r6wiHBPVAy0z5bq5XyMqFY7G9F/u8pAH/O3C3o3aIpuQc3lIrwyrCamPJH/pbtzoy9iI1wwacll1G+RiYatMzBt2SVcueyC/T/bf4tcUT3RtksKXuxTBwkx6mmpXiAgIB0tWsZi65abs3Z391y8Mn83MjOc8cqc9jAaVfWnq5lrdDuJcfnVZeUrWFaPieeJ8XbaslWHjIrB6kWtVJXZT58+HRMnTrTI7Esj4BfmYFDg7GJCbLQbEuJcUa1musX2qjUycPh3+2x8I1rXR19yQacnctHh0SR0e/aqxfb/PdQA/5sThXu65peQZGc6yBKMwi31RdsF8dxkgh1TMHp+FO59OBlT+tSVLaHVqEtIOJKTXHHwj8o3ZfSvLtiN3FwHzJ3dHrm5aqzn1sY1up0rEa6y6qzFfSkIO+0h13mUM6JBizT8+IVlw18iW1BVsHd1dZVLaRk89rzsUx8X4wYPzzx07HYFTe9KxMujWsnGUt+sroH+I8Jkth8W6oXOPaNl8J8/pRnswYdzq+CerskIqJaLq1ec8PniynB0ADo+nojy/sZbNsoTre4Dq+c3vmvZIRUfvVoF771UDY8NiZddCje8FyDr65vfl2bXxcIPPp6IOc/VQmaag7mOND3VUfbpVks9dpeu4fhle02Lhnci0M9fuAuurka88Xp7+Vwsguhzr5ZGelq4RqLrXZWa2RaN8mo3ypCNDOOjXbHxk0roOzYa0eGuMviLrndX41ywz6IvvgrOsVCvG9Ewt3bjzPxzjFJ/SYyJXe9I8PHLwaRXTsKvQjbS05wQft5LBvpjf+Rn7t+vrQEXVxOGTwqFl0+uDPozRrbClcj8O3lbS4hxxsJRNZGa6Cjr6EXd+9LN52SgL4rqwdmYuyoMa94KxPie9WBwUFC3SSbmr7kI/0q3785naz0H55dYLP72+vgC8vn4IGzf4Ac1aNkqFpUqZWDbz5ZF+HXqJqJBw2vy55Wrf7TYNmhAD8TF2r5hqF6uUb1m6Vi0/nqbl//NipCP27/yx5uTa+OrFYGyn/oLC/9GOW8jTh32wsyB9VTTx16o1zwTb3xz/RqNmBstH7et98WbE6pD7RQrZ70Tr1crg6KI8dRsIy0tDRcu5A9O0bJlS7z11lt48MEH4efnh+rV//uDJYrxRd19p4Dn4eSg/rvOAj8d2watCanSAlri0KQBtMZ00nKkRS0wOGvne6GAkquebrBFkafkYhe+R3JyMry9S6ePf8o/sWL47ifhUu7O21DkpOXiwwe+KtVj1WRmf/jwYRncCxTUxw8aNAirVq2y4ZEREZHWGGGQizWvVyubBvuOHTvChgULRESkIybFunp38Xq1Um8FBBERERUJG+gREZEumKxsoGfNa22NwZ6IiHTBBINcrHm9WjHYExGRLhitHAVPzSPoqbdMgoiIiIqEmT0REemCiXX2REREOqizV/RZZ6/e2xQiIiIqEmb2RESkC4qVrfHF69WKmT0REemC6Z9Z76xZ7tRrr70Gg8GA8ePHm9dlZWVh9OjR8Pf3R7ly5fDEE08gNjbW4nWXL19G9+7d4eHhgYCAAEyZMgV5ecWfmIzBnoiIqBQdOnQIH3zwAZo1s5wOfcKECfjhhx/w1VdfYffu3YiOjkbv3r3N241Gowz0OTk52LdvH1avXi3njZk1a1axj4HBnoiIdNUa32TFciezu/br1w8fffQRfH19zevFzHmffPKJnO31oYceQuvWrfHpp5/KoH7gwAG5z7Zt23D69Gl88cUXaNGiBbp164ZXXnkFy5YtkzcAxcFgT0REumCyQTG+KKYX2Xnnzp0t1h85cgS5ubkW6xs0aCCnd9+/f798Lh6bNm2KSpUqmfcJCQmRU/aeOnWqWMfBBnpERETFIIJtYa6urnK50bp163D06FFZjH+jK1euwMXFBeXLl7dYLwK72FawT+FAX7C9YFtxMLMnIiJdjY1vsmIRgoKC4OPjY14WLlx40++KiIjAuHHjsGbNGri5ucHWmNkTEZEumKxsUV/wWhHIvb29zetvldWLYvq4uDi0atXKosHdnj178N577+Hnn3+W9e5JSUkW2b1ojR8YGCh/Fo8HDx60eN+C1voF+xQVM3siItIFUwnV2YtAX3i5VbDv1KkTTpw4gePHj5uXu+66SzbWK/jZ2dkZO3bsML8mNDRUdrVr166dfC4exXuIm4YC27dvl7+zUaNGxTp3ZvZEREQlzMvLC02aNLFY5+npKfvUF6wfOnQoJk6cCD8/PxnAx44dKwP8PffcI7d37dpVBvUBAwZg0aJFsp5+5syZstHfrW4w/g2DPRER6YKphIrxS8qSJUvg4OAgB9PJzs6WLe2XL19u3u7o6IjNmzdj5MiR8iZA3CwMGjQI8+bNK/bvYrAnIiJdMNk42O/atcviuWi4J/rMi+V2atSogZ9++gnW0kSwN8bFw2BwhlaEVGkBzTGod0zpWzGdPGvrQ6AiUHKLN/CIKmjsbwmihbti62PQPk0EeyIiov+iWDlNrZrvSRjsiYhIF0x2Vmdfltj1joiISOOY2RMRkS6YdJzZM9gTEZEumHQc7FmMT0REpHHM7ImISBdMOs7sGeyJiEgXFMUgF2ter1YM9kREpAumQtPU3unr1Yp19kRERBrHzJ6IiHTBxDp7IiIibVN0XGfPYnwiIiKNY2ZPRES6YGIxPhERkbYpLMYnIiIirWJmT0REuqBYWYyv5syewZ6IiHRBkQHbuterFYvxiYiINI6Z/b94ekws7nskGUF1s5GT5YDThz3wyfzKiLzoBrXrOTgBfUbGwa9iHsJOu2P5zKoIPe4BtXtqdCyGvhSDjR9XwIrZ1aBmWrtGTdqm4clR8QhumgH/wDzMGVIT+7f6QM20dk49Biag+4AEVArKkc8vnXPDmiWBOLzTG1pggkH+s+b1asXM/l80a5eOH1ZVwPgewZj+TG04OilY8GUYXN2NULMHHk3E8NnRWPNWIEaH1EPYaTfMXxsGH/9cqFm95hno3v+qPB+10+I1cvMwIeyUG957Sd03YVo+p/gYZ6xcWAVjutXH2Efq4c/fvTBnZThq1MuEllrjK1YsamXTYL9w4UK0adMGXl5eCAgIQK9evRAaGgp7MaNfbWzf4CfvbkVm9eb46qhULRfBzdT9we89PAFb1/ph23o/XD7vhnemVkN2pgEhfa9Brdw8jJj63iUsfTEIqUmOUDstXiORHa5eVBn7VJz5av2c/tjug0O/eiM63BVRYW5Y9XplZKU7oEGrDGipn73JikWtbBrsd+/ejdGjR+PAgQPYvn07cnNz0bVrV6Snp8MeeXrnZ/RqDiZOziYEN8vA0b1e5nXibvXYXi80aq3eP+gxCyJxcIe3PA+10+o1InVxcFBkCZOrhwlnjnja+nBIzXX2W7dutXi+atUqmeEfOXIEHTp0gD0xGBSMmBuFkwc9cCnUHWrl7WeEoxOQFG956RMTnGTbBDUSX0h1m2RibPd60AItXiNSj5oNMrF003m4uJqQme6Aec/XkqVLWqAoVrbGV3FzfLtqoJecnCwf/fz8brk9OztbLgVSUlLK7NjGLIhCjQZZmNSrbpn9TvpvFavkYOS8KEzvWwe52WyCQmStyIuuGNW1Pjy8jLi/exImL72EKU8EayLgKzoeQc9ugr3JZML48eNx3333oUmTJret4587d26ZH9vo+ZFo2yUFkx6vg4QYF6hZyjVHGPOA8hXzLNb7VshD4g2ZpBrUbZoB34p5WLb1elsPkRU3vScdjw5OQI9azWEyqesPVGvXiNQlL9cB0X+7yp8vnPBA/RYZ6PV8PN6ZGmTrQyMr2E0qJOruT548iXXr1t12n+nTp8vsv2CJiIgo5aNSZKC/9+FkvPhkHcRG5P8BqP0P+fxfHmjZPtWiiqJF+zScPqK+bl3Hf/PC8IfqY2TX60vocXf8utFX/qy2QK/Fa0TqZnAAnF1M0AJFx63x7SJNGDNmDDZv3ow9e/agWrXbd2FxdXWVS5kd14IoPPh4IuY8VwuZaQ7wrZjf7Sk91VH2u1erbz+sgMlLI3DuTw+EHvPA48PiZReibetuXX1izzLTHW9qQ5GV4YDUxJvXq4mWrlHhHhNVauX33xYCg3JQu3GmbPAaH6XOEjOtndNz06JxaKc34qOc4V7OhAd7JaJZuzTMeLYOtMCkGGDgrHdlT1EUjB07Fhs3bsSuXbtQq1Yt2JOeg6/Kx8XfXrRYv3h8kOySp1a7N/nCx9+IgVOuyCLwsFPumNGvFpISnG19aKTha1SveSbe+Ob639KIudHycdt6X7w5oTrUSGvnVL5CHqa8fQl+AXnISHVE+Bk3GegL9wwhdTIoIuLayKhRo7B27Vp8//33qF+/vnm9j48P3N3/OysTDfTEvh3xGJwM6v0S1AWDeu+INdcsl9RNY39LeUoudinfyapZb+/SGakv5Z9YUW/NNDh63HnpsDEjG+f6vVaqx1pabFoW/f7778v/tI4dO6Jy5crmZf369bY8LCIi0iBFdr2zps4eqmXzYnwiIiLSQQM9IiKi0qawnz0REZEO5rOHda9XKwZ7IiLSBUXHmb16O4sTERFRkTCzJyIifVD0W47PYE9ERPqgWDnkLYvxiYiIyF4xsyciIl1QOJ89ERGRtilsjU9ERERaxcyeiIj0QTFY18hOxZk9gz0REemCouM6exbjExERaRwzeyIi0geFg+r8q02bNhX5DR999FFrjoeIiKhUKDpujV+kYN+rV68ivZnBYIDRaLT2mIiIiEqHAl0qUrA3mUylfyRERERkf3X2WVlZcHNzK7mjISIiKiWKjovxi90aXxTTv/LKK6hatSrKlSuHsLAwuf7ll1/GJ598UhrHSEREVHIN9BQrFr1k9vPnz8fq1auxaNEiDBs2zLy+SZMmWLp0KYYOHYqyZnBygsGgoY4FBu31iFRyc6AlSrvm0BrD/j9tfQik9c7eejgfO1XsqPLZZ5/hww8/RL9+/eDo6Ghe37x5c5w9e7akj4+IiKiEGEpgUadip8NRUVGoW7fuLRvx5ebmltRxERERlSxFv/3si53ZN2rUCHv37r1p/ddff42WLVuW1HERERGRrTL7WbNmYdCgQTLDF9n8t99+i9DQUFm8v3nz5pI6LiIiopKlMLMvssceeww//PADfvnlF3h6esrgf+bMGbmuS5cupXOUREREJTXrnWLFUgzvv/8+mjVrBm9vb7m0a9cOW7Zssei+Pnr0aPj7+8vebU888QRiY2Mt3uPy5cvo3r07PDw8EBAQgClTpiAvL6/Yp35HTdjvv/9+bN++/U5eSkREpAvVqlXDa6+9huDgYCiKInuyiYT52LFjaNy4MSZMmIAff/wRX331FXx8fDBmzBj07t0bv//+u7mruwj0gYGB2LdvH2JiYjBw4EA4OztjwYIFxTqWO+6vdvjwYZnRF9Tjt27d+k7fioiISHNT3Pbs2fOmrusi2z9w4IC8ERBj06xduxYPPfSQ3P7pp5+iYcOGcvs999yDbdu24fTp07IkvVKlSmjRooUc52bq1KmYM2cOXFxcSq8YPzIyUmb2d999N8aNGyeXNm3aoH379nIbERGRlgfVSUlJsViys7P/81eLLH3dunVIT0+XxflHjhyRPdg6d+5s3qdBgwaoXr069u/fL5+Lx6ZNm8pAXyAkJET+zlOnThXr1Isd7J9//nl5gCKrv3btmlzEz6KxnthGRESk5Tr7oKAgWexesCxcuPC2v/LEiROyPt7V1RUjRozAxo0bZWn4lStXZGZevnx5i/1FYBfbBPFYONAXbC/YVqrF+Lt375Z1B/Xr1zevEz+/++67MuMnIiLSsoiICNngroAI5Lcj4uPx48eRnJwsu6iL3mwijpa1Ygd7cUdzq8FzRBFFlSpVSuq4iIiISpRByV+seb1Q0Lq+KET2XjAQnWjbdujQIbz99tt4+umnkZOTg6SkJIvsXrTGFw3yBPF48OBBi/craK1fsE+pFeO/8cYbGDt2rGygV0D8LOruFy9eXNy3IyIi0s1EOCaTSdbxi8AvWtXv2LHDvE2MWSO62ok6fUE8imqAuLg48z6iJ5y40RBVASWe2fv6+sJguN6/UDQwaNu2LZyc8l8u+vyJn4cMGYJevXoV6wCIiIi0aPr06ejWrZtsdJeamipb3u/atQs///yzrOsXE8dNnDgRfn5+MoCLRFoEeNESX+jatasM6gMGDJCTz4l6+pkzZ8q++f9WdXDHwV7MZkdERKRqSvEHxrnp9cUgMnLRL170jxfBXQywIwJ9wQB0S5YsgYODgxxMR2T7oqX98uXLza8Xk82JkWlHjhwpbwLEQHaizn/evHnFPnSDInr6q5TofiD+Ax90egJOBmdoBqe4tXuc4paoZOQpudiF72UDtqLWg99prAh66xU4uLvd8fuYMrMQMfHlUj3W0mLVJPBiqD/RwKAwtf0HEBERaV2xU0hRXy+G9BNj9IoiBVGfX3ghIiKyS4rtG+ipJti/+OKL+PXXX+WQf6KBwMcff4y5c+fKbndi5jsiIiK7pOg32Be7GF/MbieCeseOHfHcc8/JgXREH8IaNWpgzZo16NevX+kcKREREZVNZi+Gx61du7a5fl48F8TY+Hv27LmzoyAiItLYFLeqzuxFoA8PD5f9BsWg/Rs2bJCT4oiM/8YxftXOwUFB/wnReOjxa/ANyMXVWGf88lUFrH1HjFyk3ovu7mnEwElRuDckEeUr5OLiKQ+smFMd5/4qBzXrOTgBfUbGwa9iHsJOu2P5zKoIPe4BNXB3y8WgvsdxX9vLKO+dhQvhfnh/ZRucu1hBbh/w1HF0bP83KvpnIDfPAefD/LBqbUucPV8RaqLma3QrTdqm4clR8QhumgH/wDzMGVIT+7f6QK20dj6lNYKeLjJ7UXT/55/5XXSmTZuGZcuWwc3NTc7LO2XKlGK9l6j3F/0OC4YeFP0It2zZAnvx5Mgr6D4gHstnVcfwhxpj5cJq6DPiCh57Lh5qNv71cLS6PxlvTKiNEV2b4OgeHyxccw7+ldTbPe6BRxMxfHY01rwViNEh9RB22g3z14bBx//moZ3t0YRR+9CqeTQWvdMe/5vYE0f/rIzXZ2+Hv1+G3B4Z7Y33Pr4bwyf2xMSZDyM2rhwWvvwLfLyzoBZqv0a34uZhQtgpN7z3UjVogdbO5yYK6+yLTAT1AmJqvrNnz8qp+kS9vQjcxSHm833ttdcQHBwM0d1/9erVeOyxx3Ds2DE0btwYttbornQc2FYeB3/Nv7ONjXRFx0evoX7zdKiVi6sJ7bslYu6wYJw86CXXfbG0Ktp2TkKPAXFYvVidf+S9hydg61o/bFvvJ5+/M7Ua7u6UgpC+17DhPctZo+yNi0se7r/nMma/9iBOnM4/1s83tMA9d0WiZ0goVn3ZEjt/y686K/DBqrvQrfMF1KqRiOMnKkMN1HyNbufwTm+5aIXWzoeus3r0FtEwr3fv3sUO9ELPnj3xyCOPyGBfr149zJ8/X04FeODAAdiD04c90eK+VFStlZ891WqYgcZt0nBol3r/GBydFDg6ATnZlpc+J8sBje9Kgxo5OZsQ3CwDR/fm37wIimLAsb1eaNQ6PzO2Z44OChwdFeTkOlqsz85xROMG18fELuDkZMQjXc4jLd0ZYX+ro7ur2q8RkdoVKbN/5513ivyGL7zwwh0diJg176uvvpL9+AsmAbC1DcsD4eFlxEc7T8FkBBwcgdVvVMHO7/yhVpnpjjh9xBPPjo3G5fNuSEpwRsfHrqJBqzTE/H3nI0vZkrefUd7AJMVbfpwTE5wQVDcb9i4zyxmnzlZEvz5/4XKkD5KS3fBg+7/RsF4Coq9cD45tW0fipQl74Oqah2uJ7pg2twtSUtVxzdR+jUgbDFbWuxu0HuzF+L1FISbLKW6wFzP6iOAuRuMTWf3GjRtvO5uPGDtYLIWHQCxNHXok4qFe1/D62Fq4dM4ddRpn4H+zI3A11gW/fK3egP/G+NqY8MbfWHvoTxjzgAsnPbF7kx/qNmWGZSuirn7S6H1Y9/HXMBoNsgHert9qIrhOfm8X4c+TlTBycg94e2XLzH7mpD14YVo3JKW42/TYiUgjwV60vi8t9evXx/Hjx+VYw19//bUc5H/37t23DPgLFy6UA/iUlednRMrsfvcP+XWMf4e6I6BqDp4eFaPqYB9z2Q0vPt0Aru5GeHoZcS3OBdPfu4Arl4s3i5K9SLnmKG9aylfMs1jvWyEPiTdkkvYqJtYLk2eFwM01Fx7uubiW5IGXJu5GTOz1HhJZ2c6IviIWyFb4n763EQ93uoB1G5vC3mnhGpEGKGU7EY49sfmMKy4uLrJxn5jbVwTz5s2b4+23377tdIHipqBgiYiIKNVjc3U3wWSyvLgmk3bmqcnOdJSBvpx3Hlp3SMH+bersOpmX64Dzf3mgZftU8zqDQUGL9mk4fURd3bpEQBeBvpxnNu5qEY39h4Juu684R2dnI9RAS9eIVExha3y7YTKZLIrqCxPD8xZ3Dl9r/PFLeTwzNgbx0S64dM5NFuM//nwctm1Qb1YvtO6QLCufIsPcUKVGFp5/KQIRF92w7av8Pt1q9O2HFTB5aQTO/emB0GMeeHxYvOxGtG1dfqmMvWvdIkrWB4oudlUCUzFs4BFERPng51/rymy/7xMnZOC/luQOH69s9Hz4LCr4ZWDP/ppQC7Vfo1tx8zCiSq3rXVYDg3JQu3EmUpMcER/lArXR2vmQnQR7kal369ZNDtCTmpqKtWvXYteuXXK+X3uwfFYQBk6OxuhXL8vBZ8SgOlvWVMCat9XR1el2RKPD56ZGokJgDtKSnfDbFl+seqMqjHnqLbLYvckXPv5GDJxyBb5iwJZT7pjRr5ZsgKgGnh65GNLvKCr4ZyA1zRW/HaiOT9e2hNHoIAd3Cqqagi4dd8HbOxupqa4IveAv+9tfilBPaYzar9Gt1GueiTe+uWh+PmJutHzctt4Xb06oDrXR2vncRLEyO1dxZm/T+eyHDh2KHTt2ICYmRs41LLrvTZ06FV26dCnS6zmfvXpwPnv7x/nsSevz2decPx8OblbMZ5+Vhb9nzNDffPbW+uSTT2z564mIiHThjlLIvXv3on///rLLXFRUlFz3+eef47fffivp4yMiIioZin4b6BU72H/zzTcICQmBu7u7HNa2oDGdKNZYsGBBaRwjERGR9RQG+yJ79dVXsWLFCnz00Udwdr5eT37ffffh6NGjJX18REREJTrrncGKRTfBPjQ0FB06dLhpvWj8kJSUVFLHRURERLYK9oGBgbhw4cJN60V9vZjrnoiIyK5H0FOsWPQS7IcNG4Zx48bhjz/+kGPhR0dHY82aNZg8eTJGjhxZOkdJRERkLUW/dfbF7no3bdo0Ocpdp06dkJGRIYv0xah2ItiPHTu2dI6SiIiIyi7Yi2x+xowZmDJliizOT0tLk5PWiBnriIiI7JXBykZ2am6g52TNBDa3m4qWiIjI7uh4uNxiB/sHH3xQZve38+uvv1p7TERERGTLYN+iRQuL57m5uXI++pMnT8q56ImIiOySYmVRvJ4y+yVLltxy/Zw5c2T9PRERkV1S9FuMX2LTq4mx8leuXFlSb0dERET2Nuvd/v374WbF1IFERESlStFvZl/sYN+7d2+L54qiyPnoDx8+jJdffrkkj42IiKjEGNj1rujEGPiFOTg4oH79+pg3bx66du1aksdGREREZR3sjUYjnnvuOTRt2hS+vr4l8fuJiIjInhroOTo6yuyds9sREZHqKPodG7/YrfGbNGmCsLCw0jkaIiKiUmLgfPZF9+qrr8pJbzZv3iwb5qWkpFgsREREpNI6e9EAb9KkSXjkkUfk80cffdRi2FzRKl88F/X6ZU3Jy4PyL0P4EpU0w/4/oTUGV1dojZKdbetDIHujQJeKHOznzp2LESNGYOfOnaV7RERERKVBYT/7/yQyd+GBBx4ozeMhIiIiW3a9+7fZ7oiIiOyZgYPqFE29evX+M+Bfu3bN2mMiIiIqeQqL8Ytcb3/jCHpERESkoWD/zDPPICAgoPSOhoiIqJQYWIz/31hfT0REqqawGL/IrfGJiIhUSWGw/08mk6l0j4SIiIjsY4pbIiIiNTKwzp6IiEjjFP0W4xd7IhwiIiJSF2b2RESkD4p+M3sGeyIi0gWDjuvsWYxPRESkcczsiYhIHxQW4xMREWmagcX4REREpFUM9kREpK9ifMWKpRgWLlyINm3awMvLS04i16tXL4SGhlrsk5WVhdGjR8Pf3x/lypXDE088gdjYWIt9Ll++jO7du8PDw0O+z5QpU5CXl1esY2GwJyIifVDKNtjv3r1bBvIDBw5g+/btyM3NRdeuXZGenm7eZ8KECfjhhx/w1Vdfyf2jo6PRu3dv83aj0SgDfU5ODvbt24fVq1dj1apVmDVrVrGOxaCoeIablJQU+Pj4oCMeg5PBudR+T8/BCegzMg5+FfMQdtody2dWRehxD6jR02Nicd8jyQiqm42cLAecPuyBT+ZXRuRFN6idlq6TLc7H4Opaou/X5O4U9Bl+BcFN0uFfKRdzhwdj/3Zfuc3RyYRBk6LQpmMSKlfPRnqqI4797o2VrwfhWpxLiR2Dkp2N0qa1z11Zn1Oekotd+B7Jycnw9vYu1VjRaNQCOLre+XedMTsLp5e/dMfHGh8fLzNzEdQ7dOgg36dixYpYu3Yt+vTpI/c5e/YsGjZsiP379+Oee+7Bli1b0KNHD3kTUKlSJbnPihUrMHXqVPl+Li4u6srsX3vtNTmN7vjx42FPHng0EcNnR2PNW4EYHVIPYafdMH9tGHz8c6FGzdql44dVFTC+RzCmP1Mbjk4KFnwZBld3I9RMa9dJC+fj5m5C+BkPLJtV46Ztru4m1G2SjrXvVcGYno3xyohgVKudhTkfnYOaaOE66eGc7IUI7oKfn598PHLkiMz2O3fubN6nQYMGqF69ugz2gnhs2rSpOdALISEh8gbm1KlTRf7ddhHsDx06hA8++ADNmjWDvek9PAFb1/ph23o/XD7vhnemVkN2pgEhfa9BjWb0q43tG/xw6ZybvGN/c3x1VKqWi+BmmVAzrV0nLZzP4d3lsfrNati3Lf+LrbCMVCe8NKAB9v7oj8gwd5w9Xg7LZ9dAvWYZqFil9LPxkqKF66SHcyrpYnwRaAsv2UUoQRIzx4pk9r777kOTJk3kuitXrsjMvHz58hb7isAuthXsUzjQF2wv2KaaYJ+WloZ+/frho48+gq9vfhGfvXByNiG4WQaO7vUyr1MUA47t9UKj1hnQAk/v/Iw+NckRaqW166S18ykqTy8jxEza6Snq6BGsxeukxXO6Vdc7gxWLEBQUJKsFChbREO+/iLr7kydPYt26dbAFmwd78R8gGh8ULsawF95+Rjg6AUnxll8+iQlO8K1YvJaQ9shgUDBibhROHvTApVB3qJXWrpPWzqconF1MGDI1Ars2+SMjTR03nlq8Tlo8p9IQEREhi+QLlunTp//r/mPGjMHmzZuxc+dOVKtWzbw+MDBQNrxLSkqy2F+0xhfbCva5sXV+wfOCfew+2Is7nKNHjxbprkgQRSU3Fp/QnRuzIAo1GmRh4cib61SJyoporDdj2QUYDMB7L9e09eGQliklU4wvGucVXlxv07hVtH8XgX7jxo349ddfUatWLYvtrVu3hrOzM3bs2GFeJ7rmia527dq1k8/F44kTJxAXF2feR7TsF7+3UaNGRT51J1veGY0bN04etJtb0VpHipuCuXPnoqykXHOEMQ8of8MdrW+FPCTecOerNqPnR6JtlxRMerwOEmJKrvWzLWjtOmntfP4r0L/03kUEVM3G1GcbqCar1+p10uI53UQp25Jr0dL++++/l33tC+rYRdG/u7u7fBw6dCgmTpwoG+2JAD527FgZ4EVLfEF01RNBfcCAAVi0aJF8j5kzZ8r3vt1Nhl1l9qIVorhTadWqFZycnOQiuiO888478mfRt/BGoqikcNGJuGEoTXm5Djj/lwdatk+1KPpu0T4Np4+otWuNIgP9vQ8n48Un6yA2omS7W9mC1q6T1s7nvwJ91ZpZmN6/AVKTSq/7bGnQ4nXS4jnZ0vvvvy9jVceOHVG5cmXzsn79evM+S5YskV3rxGA6ojueKJr/9ttvzdsdHR1lFYB4FDcB/fv3x8CBAzFv3rxiHYvNbtU6deokiyYKe+6552S3A9F/UJzYjcRdTHHuZErCtx9WwOSlETj3pwdCj3ng8WHxcPMwYdu6m1sYq6Xo/sHHEzHnuVrITHOAb8X87jSin7Pod69WWrtOWjgfNw8jqtTIMj8PDMpG7YbpSE12wrU4Z8xcfgF1G2dg1vP14OCgwLdCjtxPbBdBRw20cJ30cE62Ghu/KMPYiJLtZcuWyeV2atSogZ9++gnWsFmwF0UaBd0PCnh6esohA29cb0u7N/nCx9+IgVOuyAYqYafcMaNfLSQlqCsLKdBz8FX5uPjbixbrF48Pkl3y1Epr10kL51OvaToWrTtrfv6/ly/Lx+1fV8AXS6uiXZf8Rknv/3TS4nUvPtMAf/1ROoOrlDQtXCc9nJOZjme9s6sR9ERRR4sWLbB06VK7GkGPSA9KegQ9e1AWI+iRekbQa/r8Aji6WDGCXk4WTnx85yPo2ZJdtbjYtWuXrQ+BiIhIc+wq2BMREZUaRb/F+Az2RESkC4YybqBnT9TR5JWIiIjuGDN7IiLSB4XF+ERERNqm6DfYsxifiIhI45jZExGRLhh03ECPwZ6IiPRBYTE+ERERaRQzeyIi0gWDosjFmterFYM9ERHpg6LfYnwGeyIi0gWDjhvosc6eiIhI45jZExGRPigsxiciItI0A4vxiYiISKuY2RMRkT4oLMYnIiLSNAOL8YmIiEirmNkTEZE+KCzGJyKdU7KzoTVOQdWgNXmRUdAWQ5kGUYOKA7Y1WIxPRESkcczsiYhIHxQlf7Hm9SrFYE9ERLpg0HFrfAZ7IiLSB0W/DfRYZ09ERKRxzOyJiEgXDKb8xZrXqxWDPRER6YPCYnwiIiLSKGb2RESkCwa2xiciItI4Rb/97FmMT0REpHHM7ImISBcMLMYnIiLSOIWt8YmIiEijmNkTEZEuGFiMT0REpHGKflvjM9gTEZEuGHSc2bPOnoiISOOY2RMRkT4o+m2Nz2BfBD0HJ6DPyDj4VcxD2Gl3LJ9ZFaHHPaBmPCf71qRtGp4cFY/gphnwD8zDnCE1sX+rD9ROK9foyYEXMHh0KL5bVxMfLWmMgMoZ+PS7nbfcd+H0Vvjt18pQo6dGx2LoSzHY+HEFrJhdDWpnYDE+3c4DjyZi+OxorHkrEKND6iHstBvmrw2Dj38u1IrnZP/cPEwIO+WG915S/xes1q5RcMMkPPz4ZYSd9zKvS4h1R/9unSyWLz6sh4x0RxzeXxFqVK95Brr3vyqvE6mfTYP9nDlzYDAYLJYGDRrAnvQenoCta/2wbb0fLp93wztTqyE704CQvtegVjwn+3d4pzdWL6qMfRrI5rV0jdzc8zBl3nG8u6AZ0lKczetNJgMSr7lZLO0euILfdlRGVqb6ClDdPIyY+t4lLH0xCKlJjtAMk2L9olI2z+wbN26MmJgY8/Lbb7/BXjg5mxDcLANH916/g1cUA47t9UKj1hlQI54T2YJWrtHIKSdx6PcAHD9U4V/3q9sgGXXqp2DbpiCo0ZgFkTi4w1teH03W2StWLCpl81tOJycnBAYGwh55+xnh6AQkxVv+NyUmOCGobjbUiOdEtqCFa9ShSzTq1k/B+Ofu+899u/a8jMvh5XDmhB/UWN1St0kmxnavZ+tDIS1l9ufPn0eVKlVQu3Zt9OvXD5cvX77tvtnZ2UhJSbFYiIhKW4WATAyfeApvzG6B3Jx/L9Z2cTXigZBoVWb1FavkYOS8KLw+tgZys20eHkqcoVAjvTtaoF42zezbtm2LVatWoX79+rIIf+7cubj//vtx8uRJeHndXHy0cOFCuU9ZSbnmCGMeUL5insV63wp5SLwhQ1ELnhPZgtqvkSiW9/XLwTurr1czOjopaNLyGnr2uYRe93eT9fbCfQ/FwNXNiB0/VYXa1G2aAd+KeVi2NdS8TpTINL0nHY8OTkCPWs3N56lKCkfQs4lu3bqZf27WrJkM/jVq1MCGDRswdOjQm/afPn06Jk6caH4uMvugoNK7e87LdcD5vzzQsn2quduTwaCgRfs0bFrlDzXiOZEtqP0a/Xm4Akb17WCxbvzLfyLyUjl8/VkdiwDYtWcE/thbCSlJrlCb4795YfhD9S3WTXrrMiIuumHDsgB1B3qds6tb6vLly6NevXq4cOHCLbe7urrKpSx9+2EFTF4agXN/eiD0mAceHxYvu0VtW6e+urgCPCd1tIauUivH/DwwKAe1G2fKltHxUS5QIzVfo8wMJ1wKsyxtzMp0REqys8X6ytXSZbY/Z0IbqFFmuiMuhbpbrMvKcEBq4s3r1cig4372dhXs09LScPHiRQwYMAD2YvcmX/j4GzFwyhVZvBV2yh0z+tVCUsL1bjdqw3Oyf/WaZ+KNby6an4+YGy0ft633xZsTqkONtHaNbqVLzwgkxLnh6B/q7FuveYp+R9AzKIrtKiEmT56Mnj17yqL76OhozJ49G8ePH8fp06dRseJ//7GIYnwfHx90xGNwMmjnC4OISoZTkHYGJSqQFxkFLclTcrFL+Q7Jycnw9vYuld+R8k+suL/jbDg53fkgQXl5Wdi7a26pHqsmM/vIyEj07dsXV69elcG9ffv2OHDgQJECPREREakg2K9bt86Wv56IiPTE9M9izetVyq7q7ImIiEqLQVHkYs3r1Up7oyYQERHZgT179sh2aWLgODH3y3fffWexXTSZmzVrFipXrgx3d3d07txZDjRX2LVr1+SAc6KNgOixJrqli8bsxcVgT0RE+qCU7dj46enpaN68OZYtW3bL7YsWLcI777yDFStW4I8//oCnpydCQkKQlZVl3kcE+lOnTmH79u3YvHmzvIEYPnx4sU+dxfhERKQPStmOoCcGjis8eJzlWylYunQpZs6ciccee0yu++yzz1CpUiVZAvDMM8/gzJkz2Lp1Kw4dOoS77rpL7vPuu+/ikUceweLFi2WJQVExsyciIiqGG+doEfO2FFd4eDiuXLkii+4LiO6BYiTZ/fv3y+fiURTdFwR6Qezv4OAgSwKKg8GeiIh0wWDNJDiFRt8Tw7SLwFywiHlbiksEekFk8oWJ5wXbxGNAQMBNM8X6+fmZ9ykqFuMTEZE+KCVTjB8REWExqE5ZD+N+J5jZExERFYMI9IWXOwn2gYGB8jE2NtZivXhesE08xsXFWWzPy8uTLfQL9ikqBnsiItIFg8n6paTUqlVLBuwdO3aY14n6f1EX365dO/lcPCYlJeHIkSPmfX799VeYTCZZt18cLMYnIiJ9UMq2Nb7oD194FlfRKE/M/yLq3KtXr47x48fj1VdfRXBwsAz+L7/8smxh36tXL7l/w4YN8fDDD2PYsGGye15ubi7GjBkjW+oXpyW+wGBPRET6oJTtrHeHDx/Ggw8+aH4+ceJE+Tho0CCsWrUKL774ouyLL/rNiwxezA8jutq5uV2frGfNmjUywHfq1Em2wn/iiSdk3/ziYrAnIiIqBR07dpT96W9HjKo3b948udyOKAVYu3at1cfCYE9ERLpg0PHY+Az2RESkD0rZ1tnbE7bGJyIi0jhm9kREpA8iMbem+5x6E3sGeyIi0geDjuvsWYxPRESkcczsiYhIR/3sFeter1IM9kREpA+KflvjayPYGwz5i1ao+AOlG1r6vGn4c5cXEQmtcSzvAy1RlBwgydZHoX3aCPZERET/xSRu1K18vUox2BMRkS4YdNwan8GeiIj0QdFvnT273hEREWkcM3siItIHRb+ZPYM9ERHpg6LfYM9ifCIiIo1jZk9ERPpgYtc7IiIiTTPouOsdi/GJiIg0jpk9ERHpg6LfBnoM9kREpA8mRZTFW/d6lWIxPhERkcYxsyciIn1QWIxPRESkcYqVAZvBnoiIyL4p+s3sWWdPRESkcczsiYhIH0wiM9dna3wGeyIi0gfFlL9Y83qVYrD/Fz0GJqD7gARUCsqRzy+dc8OaJYE4vNMbatdzcAL6jIyDX8U8hJ12x/KZVRF63ANqpqVz0upnT0vXSGjSNg1PjopHcNMM+AfmYc6Qmti/1Qdq8dSwy7i3cwKq1c5ETpYDzhz3xso3ayHq7+vX5LVVf6LZ3ckWr/tpfWW8NzfYBkdMd4p19v8iPsYZKxdWwZhu9TH2kXr483cvzFkZjhr1MqFmDzyaiOGzo7HmrUCMDqmHsNNumL82DD7+uVArrZ2TFj97WrtGgpuHCWGn3PDeS9WgRk3uSsbmL6tgYt8WmPF8Uzg6KZj/8Qm4uhst9tuyIRD9OtxjXj5ZXAuqbqCnWLGolM2DfVRUFPr37w9/f3+4u7ujadOmOHz4MOzBH9t9cOhXb0SHuyIqzA2rXq+MrHQHNGiVATXrPTwBW9f6Ydt6P1w+74Z3plZDdqYBIX2vQa20dk5a/Oxp7RoJoqRl9aLK2KeibL6wWf9ril++C8TlC54IDy2Ht16qh4Aq2QhulGqxX3aWIxITXMxLZrpKC4VNivWLStk02CcmJuK+++6Ds7MztmzZgtOnT+PNN9+Er68v7I2DgyIzE1cPE84c8YRaOTmbENwsA0f3epnXKYoBx/Z6oVFrdQYSLZ6T1j57Wr9GWuHplZ/RpyY7W6x/sEccvvx9H5Z/fxiDJ4TD1c0y8yf7Z9Pbs9dffx1BQUH49NNPzetq1bKv4qGaDTKxdNN5uLiakJnugHnP15JZiVp5+xnh6AQkxVte+sQEJwTVzYYaafGctPbZ0+o10hKDQcH/pl3EqSPeuHTh+k3lrh8DEBftimtxrqhZPw1DJoajas0MzB/XGKqj6LefvU2D/aZNmxASEoInn3wSu3fvRtWqVTFq1CgMGzbslvtnZ2fLpUBKSkqpH2PkRVeM6lofHl5G3N89CZOXXsKUJ4JV+6VL6sHPHpWlUS9fQI3gdEzu38Ji/davKpt//vu8JxLjXbDw0xMIDMrElQh3qIpiZcBWb6y3bTF+WFgY3n//fQQHB+Pnn3/GyJEj8cILL2D16tW33H/hwoXw8fExL6JUoLTl5Tog+m9XXDjhgU9fq4Lw0+7o9Xw81CrlmiOMeUD5inkW630r5CHxhqxLLbR4Tlr77Gn1GmnFyBkXcPcDVzFtcDNcjXX9133P/pXfI6RKdfU2FtUjmwZ7k8mEVq1aYcGCBWjZsiWGDx8us/oVK1bccv/p06cjOTnZvERERJT5MRscAGcXk6oDyPm/PNCyfapF8V2L9mk4fUSdXaC0eE5a++zp5RqpjyIDfbvOCZg+pDlio/47U6/TIE0+Xot3geoo+m2Nb9Nb6sqVK6NRo0YW6xo2bIhvvvnmlvu7urrKpaw8Ny0ah3Z6Iz7KGe7lTHiwVyKatUvDjGfrlNkxlIZvP6yAyUsjcO5PD4Qe88Djw+JlF6Jt6/ygVlo7Jy1+9rR2jQQ3DyOq1MofC0EIDMpB7caZSE1yRHyUiyqK7jt2j8O8MY2Rme4I3wr555Ke6oicbEdZVP9g9zgc2uOHlCRn1KqfjuFTL+LEIR/8fa4cVMckbpZNVr5enWwa7EVL/NDQUIt1586dQ40aNWAPylfIw5S3L8EvIA8ZqY4IP+Mmv2wLtyhWo92bfOHjb8TAKVfgKwY3OeWOGf1qISnBsgWummjtnLT42dPaNRLqNc/EG99cND8fMTdaPm5b74s3J1SHvevRN0Y+LvrsL4v1ogue6JKXl2tAi3ZJeGxgFNzcjYi/4orft1fAlyvs/9xuSdFvAz2Dotju6A8dOoR7770Xc+fOxVNPPYWDBw/KYvwPP/wQ/fr1+8/XiwZ6ou6+o6EXnAzq/cLQ0gdKNwwGaA4/d6rgWF6dffpvJ0/JwY6kz2XVrLd36YwQmfJPrOhccSicHO68xCXPlINf4j8p1WPVZJ19mzZtsHHjRnz55Zdo0qQJXnnlFSxdurRIgZ6IiKhYFNbZ20yPHj3kQkREVKpM+p31zubD5RIREZHGM3siIqKyoCgmuVjzerVisCciIn1QrJzMRsV19izGJyIi0jhm9kREpA+KlQ30VJzZM9gTEZE+mEyAwYp6dxXX2bMYn4iISOOY2RMRkT4oLMYnIiLSNMVkgmJFMT673hEREdk7Rb+ZPevsiYiINI6ZPRER6YNJEXO96jKzZ7AnIiJ9UESwNuky2LMYn4iISOOY2RMRkS4oJgWKFcX4CjN7IiIiO6eYrF/uwLJly1CzZk24ubmhbdu2OHjwIMoagz0REVEpWb9+PSZOnIjZs2fj6NGjaN68OUJCQhAXF4eyxGBPRET6KcY3WbcU11tvvYVhw4bhueeeQ6NGjbBixQp4eHhg5cqVKEsM9kREpA9K2Rbj5+Tk4MiRI+jcubN5nYODg3y+f/9+lCVVN9AraCyRp+RCU1TcCEQ/DNAcfu5UQVFyoCV5/5xPWTR+y0OuVQPoydcDSElJsVjv6uoqlxslJCTAaDSiUqVKFuvF87Nnz6IsqTrYp6amysff8KNVF5Co2Ph5I1tJgiaJ73MfH59SeW8XFxcEBgbitys/Wf1e5cqVQ1BQkMU6UR8/Z84c2DNVB/sqVaogIiICXl5eMBhKN9MSd3LiAovf5+3tDbXT2vkIPCd14DnZv7I8H5HRi0Avvs9Li5ubG8LDw2Wxekkc743x5lZZvVChQgU4OjoiNjbWYr14Lm4+ypKqg72o+6hWrVqZ/k7xwdfCH7NWz0fgOakDz8n+ldX5lFZGf2PAd3NzQ1kSJQqtW7fGjh070KtXL7nOZDLJ52PGjCnTY1F1sCciIrJnEydOxKBBg3DXXXfh7rvvxtKlS5Geni5b55clBnsiIqJS8vTTTyM+Ph6zZs3ClStX0KJFC2zduvWmRnuljcG+iESdjGiEcbu6GbXR2vkIPCd14DnZP62dj62JIvuyLra/kUFR82C/RERE9J84qA4REZHGMdgTERFpHIM9ERGRxjHYExERaRyD/b8Qgx+IcY1JHdjW1H7FxMTg9OnT0JKC7wYtfe4yMjJKZJQ5sj8M9rchvpgGDhwo5x0eOXIk9u3bBy3Q2s2LGJxCDLUphvcs7SGTy8q1a9fkJBnnz5/XxBdvVFQUmjZtipkzZ+Lw4cPQguPHj8sR0URw1Mrn7uTJk3jqqadw4MABZGdn2/pwqIQx2N9CaGgo7r33XhkY27RpI6ciHDduHN555x2o2blz5+ToTSLL0soNWe/evfHAAw+gYcOGWLNmjeozLfGFK6a/FF+6IkAuWrRI9Tdo4qYlOTlZLu+++y6OHj1q3qbGa/Xnn3/K74fGjRvLecnVfC4FTp06hfvvv18OP16rVi32r9ci0c+erjOZTMpLL72kPPXUU+Z1KSkpyquvvqq0aNFCef311xU1On/+vOLn56cYDAZl+vTpSnx8vKJmp06dUvz9/ZUJEyYoa9asUSZOnKg4Ozsrx44dU9R+TpMnT5Y/L168WF6vy5cvK2p29epV5dFHH1U++OADpVWrVkq/fv2UkydPym1Go1FRkz///FPx9PRUpkyZYrE+OztbUau0tDSla9euysiRI83rzpw5I/+WLl26ZNNjo5LDYH8LgwcPVjp06GCxTgR88eV71113KV988YWitj/mIUOGyPNatmyZDCDiy0qtAV8ED/Hl9MILL1is79ixozJ27FjzTZuaiGshPnPjxo0zrxPn8PDDDyv79u2TX7xqDPp5eXlKXFycUq9ePSUyMlL59ttvlTZt2ijDhg1T7r33XuWJJ55Q1CImJkYJDAxUQkJCzOc2fvx4pXv37kqDBg2UJUuWyCCpNllZWUr79u2Vo0ePynMS5yeukZeXl3LPPfcoH3/8sa0PkUoAh8u9xdSFrVq1kkWPoji/fv36cpuYRnfIkCFy3fLly/H4449bFOHZ++yAYuYlf39/OU6zmHbxmWeekdtefPFF+VxNcnNzkZSUhD59+pgbUopzFMWPor5bUFs9qjjehx9+2HxOwquvvoqff/5ZjqedkJAgi41FvXf79u2hFuK6VKxYUVaHiSoK8XcjiojFxCCiXnjYsGFQk3bt2slpX7///nusWLFCfhbFWOc1a9aU1XziHMUY6NWrV4daiL8l8b0mPmNTpkyR6z7++GNER0fj119/lZ85MStd4c8mqVBJ3DFozYULF5QKFSrIbDg1NdUiUxTZlciMt2zZoqgtuy9s3bp18jxEkXFCQoK5SDUsLExRg3Pnzpl/zsnJkY8zZ85UBgwYYLFfwfVTA1F6VODLL7+U12f9+vWyJGP37t0y25ozZ46iRgMHDlSmTZsmfx46dKji6+urNGrUSP6N/fHHH4paREdHy3Nxd3dXunTpYv7bEUR1Uvny5ZWffvpJURPx3fbMM88oY8aMUXr06KFs3brVvC0iIkLp37+/MmLECJn1q63EjK5jZn8LderUwYYNG9CtWze4u7tjzpw55uzX2dkZzZo1K5P5l0uSp6enfBSNvUS2JTJ8UZLx7LPPyqxy/PjxWLx4MS5duoTPP//c7kstgoODzVm9uCaCOJ+4uDjzPgsXLpRZ5AsvvAAnJ/v/qIvSo8IZpGi5LkqZhA4dOiAgIABHjhyBGkvLHnroIYSHh2PUqFH46aef5HmIFu0ikxRzfou/qbKea/xOVK5cWX6uqlatKhtSitKygnMUf0ti8pidO3fK7w61EMc+adIkdOzYUfYuGD58uHmbaLAnZmc7dOiQ/N5QW4kZXWf/34A28uCDD+Krr77Ck08+KVuvi9bR4gvps88+kwElKCgIauTo6Ci/nESQFEX54o93wIAB2LRpEy5evCj/qO090BcmvoAKvmwLnguiKFUUgx87dkwVgf5GNWrUkIsgrpXogleuXDn5GVSTgusiqljE/N0icGzevFk+F4vY3rx5c1UE+gJVqlTBtGnTzMcszkF8BkUVkqiyEMX6aiPmWt+yZYvs2fLhhx+idu3astpIEFUV9erVQ15envnGmtSHs979B9FNaOLEifj7779l0BDBct26dWjZsiXUrOCyiy+qTp06ySxr165dsruX2hTU2YsSGHFjJrJ+Uc8oxkYoyIzVTty8rF69Gr/88ou5VENNRMAQJUYiqIgblsI3aFohsvovv/wS27dvN9+oqc2ePXvQt29fmdGL7wJxkykSgd9++w1NmjSx9eGRFRjsi0AM2CLu2sXgLaIYT20N2m5HFOmLYlTR914Ee7VljTeaP38+Xn75ZXh7e8ugKAKL2onSpd27d8sbTBFE1HyTWXBTpjXi2oiie3GtduzYoeprJIjGel988YUcXEfcWIqqFwZ69WOw1zER7FetWiVb6qux6PFGoo777rvvli2iGzVqBC0Qg53MmzdPllqIgYPI/vz111946aWX8Prrr5uLvrVA3JwJWrxB0yMGe53TWnGqGD63oDGiVogicNaV2jdR3C0aGhLZKwZ7IiIijWP5DBERkcYx2BMREWkcgz0REZHGMdgTERFpHIM9ERGRxjHYExERaRyDPZGVBg8ejF69epmfiwlFxMRCZU0MdyzGTBBTlt6O2P7dd98V+T3FYD7WDrgkhpoWv1eM0khEtsFgT5oNwCLAiEUMdlK3bl05Ep2YzKO0ffvtt3jllVdKLEATEVlLfdOBERXRww8/jE8//RTZ2dlyWtXRo0fLkeimT59eqiOg+fn5lcj7EBGVFGb2pFliLvvAwEA5A9nIkSPl/ONiBq/CRe9i8hwxZWn9+vXl+oiICDmdcfny5WXQfuyxx2QxdOH5BMQsiGK7mMv8xRdfNM8geLtifHGzMXXqVDktsjgmUcrwySefyPcVUykLvr6+MsMXx1UwLrmYN11MA+vu7i6ngf36668tfo+4gRFTj4rt4n0KH2dRieMS7yGmNRbTmoqJhMTwvDf64IMP5PGL/cT/T3JyssX2jz/+WI7dL6Z9bdCgAZYvX17sYyGi0sNgT7ohgqLI4AuIGcrEDF9iNjkxx7oIciEhIfDy8sLevXvx+++/yznkRQlBwevefPNNOXnQypUr5bSfYjbEjRs3/uvvHThwoJz69J133sGZM2dk4BTvK4LnN998I/cRxyGm53377bflcxHoP/vsM6xYsUJOhjNhwgT0799fzoBXcFPSu3dv9OzZU9aFP//883KO9eIS5yrO5/Tp0/J3f/TRR1iyZInFPhcuXMCGDRvwww8/YOvWrTh27JicCa3AmjVr5BS84sZJnN+CBQvkTYOYkpeI7IQYG59IawYNGqQ89thj8meTyaRs375dcXV1VSZPnmzeXqlSJSU7O9v8ms8//1ypX7++3L+A2O7u7q78/PPP8nnlypWVRYsWmbfn5uYq1apVM/8u4YEHHlDGjRsnfw4NDRVpv/z9t7Jz5065PTEx0bwuKytL8fDwUPbt22ex79ChQ5W+ffvKn6dPn640atTIYvvUqVNveq8bie0bN2687fY33nhDad26tfn57NmzFUdHRyUyMtK8bsuWLYqDg4MSExMjn9epU0dZu3atxfu88sorSrt27eTP4eHh8vceO3bstr+XiEoX6+xJs0S2LjJokbGLYvFnn31Wti4v0LRpU4t6+j///FNmsSLbLSwrKwsXL16URdci+27btq15m5OTE+66666bivILiKzb0dERDzzwQJGPWxxDRkYGunTpYrFelC4UzJUuMujCxyG0a9cOxbV+/XpZ4iDOLy0tTTZg9Pb2ttinevXqqFq1qsXvEf+fojRC/F+J1w4dOhTDhg0z7yPex8fHp9jHQ0Slg8GeNEvUY7///vsyoIt6eRGYC7txKlwR7Fq3bi2LpW9UsWLFO646KC5xHMKPP/5oEWQFUedfUvbv349+/fph7ty5svpCBOd169bJqoriHqso/r/x5kPc5BCRfWCwJ80SwVw0hiuqVq1ayUw3ICDgpuy2QOXKlfHHH3+gQ4cO5gz2yJEj8rW3IkoPRBYs6tpFA8EbFZQsiIZ/BRo1aiSD+uXLl29bIiAawxU0Nixw4MABFMe+fftk48UZM2aY1126dOmm/cRxREdHyxumgt/j4OAgGzVWqlRJrg8LC5M3DkRkn9hAj+gfIlhVqFBBtsAXDfTCw8NlP/gXXngBkZGRcp9x48bhtddekwPTnD17VjZU+7c+8jVr1sSgQYMwZMgQ+ZqC9xQN3gQRbEUrfFHlEB8fLzNlUTQ+efJk2ShPNHITxeRHjx7Fu+++a270NmLECJw/fx5TpkyRxelr166VDe2KIzg4WAZykc2L3yGK82/V2FC0sBfnIKo5xP+L+P8QLfJFTwdBlAyIBoXi9efOncOJEydkl8e33nqrWMdDRKWHwZ7oH6Jb2Z49e2QdtWjpLrJnURct6uwLMv1JkyZhwIABMviJumsRmB9//PF/fV9RldCnTx95YyC6pYm67fT0dLlNFNOLYCla0ossecyYMXK9GJRHtGgXQVQch+gRIIr1RVc8QRyjaMkvbiBEtzzRal+0gi+ORx99VN5QiN8pRskTmb74nTcSpSPi/+ORRx5B165d0axZM4uudaIngOh6JwK8KMkQpRHixqPgWInI9gyilZ6tD4KIiIhKDzN7IiIijWOwJyIi0jgGeyIiIo1jsCciItI4BnsiIiKNY7AnIiLSOAZ7IiIijWOwJyIi0jgGeyIiIo1jsCciItI4BnsiIiKNY7AnIiKCtv0f416PUFs+AcMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(xticks_rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6277257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bkl       0.60      0.66      0.63       110\n",
      "          nv       0.98      0.82      0.89       671\n",
      "          df       0.57      0.36      0.44        11\n",
      "         mel       0.48      0.83      0.61       112\n",
      "        vasc       0.80      0.86      0.83        14\n",
      "         bcc       0.76      0.90      0.82        52\n",
      "       akiec       0.60      0.78      0.68        32\n",
      "\n",
      "    accuracy                           0.80      1002\n",
      "   macro avg       0.68      0.75      0.70      1002\n",
      "weighted avg       0.85      0.80      0.81      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=df['dx'].unique()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
